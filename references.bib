% AgentLeak References
% December 2025

% === AGENT SURVEYS & FRAMEWORKS ===

@article{wang2024survey,
  title={A Survey on Large Language Model based Autonomous Agents},
  author={Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and others},
  journal={Frontiers of Computer Science},
  volume={18},
  number={6},
  pages={186345},
  year={2024},
  publisher={Springer}
}

@article{xi2023rise,
  title={The Rise and Potential of Large Language Model Based Agents: A Survey},
  author={Xi, Zhiheng and Chen, Wenxiang and Guo, Xin and He, Wei and Ding, Yiwen and Hong, Boyang and Zhang, Ming and Wang, Junzhe and Jin, Senjie and Zhou, Enyu and others},
  journal={arXiv preprint arXiv:2309.07864},
  year={2023}
}

% === BENCHMARKS ===

@inproceedings{deng2009imagenet,
  title={ImageNet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={248--255},
  year={2009},
  organization={IEEE}
}

@inproceedings{wang2018glue,
  title={GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  booktitle={Proceedings of the 2018 EMNLP Workshop BlackboxNLP},
  pages={353--355},
  year={2018}
}

@article{wang2019superglue,
  title={SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems},
  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{sun2024trustllm,
  title={TrustLLM: Trustworthiness in Large Language Models},
  author={Sun, Lichao and Huang, Yue and Wang, Haoran and Wu, Siyuan and Zhang, Qihui and Gao, Chujie and Huang, Yixin and Lyu, Wenhan and Zhang, Yixuan and Li, Xiner and others},
  journal={arXiv preprint arXiv:2401.05561},
  year={2024}
}

@article{wang2023decodingtrust,
  title={DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models},
  author={Wang, Boxin and Chen, Weixin and Pei, Hengzhi and Xie, Chulin and Kang, Mintong and Zhang, Chenhui and Xu, Chejian and Xiong, Zidi and Dutta, Ritik and Schaeffer, Rylan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@article{debenedetti2024agentdojo,
  title={AgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents},
  author={Debenedetti, Edoardo and Paleka, Daniel and Kumar, Jie and Andriushchenko, Maksym and Tramèr, Florian},
  journal={arXiv preprint arXiv:2406.13352},
  year={2024}
}

% === PRIVACY ATTACKS ===

@inproceedings{carlini2021extracting,
  title={Extracting Training Data from Large Language Models},
  author={Carlini, Nicholas and Tramèr, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and others},
  booktitle={30th USENIX Security Symposium},
  pages={2633--2650},
  year={2021}
}

@article{lukas2023analyzing,
  title={Analyzing Leakage of Personally Identifiable Information in Language Models},
  author={Lukas, Nils and Salem, Ahmed and Sim, Robert and Tople, Shruti and Wutschitz, Lukas and Zanella-B{\'e}guelin, Santiago},
  journal={arXiv preprint arXiv:2302.00539},
  year={2023}
}

% === PROMPT INJECTION ===

@article{perez2022ignore,
  title={Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition},
  author={Perez, Fábio and Ribeiro, Ian},
  journal={arXiv preprint arXiv:2311.16119},
  year={2023}
}

@article{liu2023prompt,
  title={Prompt Injection attack against LLM-integrated Applications},
  author={Liu, Yi and Deng, Gelei and Xu, Zhengzi and Li, Yuekang and Zheng, Yaowen and Zhang, Ying and Zhao, Lida and Zhang, Tianwei and Liu, Yang},
  journal={arXiv preprint arXiv:2306.05499},
  year={2023}
}

@article{greshake2023youve,
  title={Not What You've Signed Up For: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection},
  author={Greshake, Kai and Abdelnabi, Sahar and Mishra, Shailesh and Endres, Christoph and Holz, Thorsten and Fritz, Mario},
  journal={arXiv preprint arXiv:2302.12173},
  year={2023}
}

@article{zou2023universal,
  title={Universal and Transferable Adversarial Attacks on Aligned Language Models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

% === DIFFERENTIAL PRIVACY ===

@inproceedings{abadi2016deep,
  title={Deep Learning with Differential Privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  booktitle={Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  pages={308--318},
  year={2016}
}

% === AGENT SAFETY ===

@article{rebedea2023nemo,
  title={NeMo Guardrails: A Toolkit for Controllable and Safe LLM Applications with Programmable Rails},
  author={Rebedea, Traian and Dinu, Razvan and Sreedhar, Makesh Narsimhan and Parisien, Christopher and Cohen, Jonathan},
  journal={arXiv preprint arXiv:2310.10501},
  year={2023}
}

@article{bai2022constitutional,
  title={Constitutional AI: Harmlessness from AI Feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{inan2023llama,
  title={Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations},
  author={Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others},
  journal={arXiv preprint arXiv:2312.06674},
  year={2023}
}

% === CONCEPT ERASURE ===

@article{belrose2023leace,
  title={LEACE: Perfect Linear Concept Erasure in Closed Form},
  author={Belrose, Nora and Schneider-Kamp, Peter and Obermayer, Klaus and Conmy, Arthur},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@inproceedings{ravfogel2020null,
  title={Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection},
  author={Ravfogel, Shauli and Elazar, Yanai and Gonen, Hila and Twiton, Michael and Goldberg, Yoav},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={7237--7256},
  year={2020}
}

% === EMBEDDING PRIVACY ===

@article{coavoux2018privacy,
  title={Privacy-preserving Neural Representations of Text},
  author={Coavoux, Maximin and Narayan, Shashi and Cohen, Shay B},
  journal={arXiv preprint arXiv:1808.09408},
  year={2018}
}

@inproceedings{elazar2018adversarial,
  title={Adversarial Removal of Demographic Attributes from Text},
  author={Elazar, Yanai and Goldberg, Yoav},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={11--21},
  year={2018}
}

% === AGENT FRAMEWORKS ===

@misc{langchain2023,
  title={LangChain: Building applications with LLMs through composability},
  author={Harrison, Chase},
  year={2023},
  howpublished={\url{https://github.com/langchain-ai/langchain}}
}

@misc{crewai2024,
  title={CrewAI: Framework for orchestrating role-playing AI agents},
  author={Moura, João},
  year={2024},
  howpublished={\url{https://github.com/joaomdmoura/crewAI}}
}

@article{hong2023metagpt,
  title={MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework},
  author={Hong, Sirui and Zhuge, Mingchen and Chen, Jonathan and Zheng, Xiawu and Cheng, Yuheng and Zhang, Ceyao and Wang, Jinlin and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and others},
  journal={arXiv preprint arXiv:2308.00352},
  year={2023}
}

@misc{autogpt2023,
  title={AutoGPT: An autonomous GPT-4 experiment},
  author={Significant-Gravitas},
  year={2023},
  howpublished={\url{https://github.com/Significant-Gravitas/AutoGPT}}
}

% === INFORMATION THEORY ===

@article{tishby2000information,
  title={The Information Bottleneck Method},
  author={Tishby, Naftali and Pereira, Fernando C and Bialek, William},
  journal={arXiv preprint physics/0004057},
  year={2000}
}

@article{xu2020usable,
  title={A Theory of Usable Information Under Computational Constraints},
  author={Xu, Yilun and Sanjabi, Maziar and Barbieri, Luca and Moerland, Thomas and Backofen, Rolf and Arjovsky, Martin},
  journal={arXiv preprint arXiv:2002.10689},
  year={2020}
}

% === EMBEDDING GEOMETRY ===

@inproceedings{ethayarajh2019contextual,
  title={How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings},
  author={Ethayarajh, Kawin},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing},
  pages={55--65},
  year={2019}
}

@article{cai2021isotropy,
  title={Isotropy in the Contextual Embedding Space: Clusters and Manifolds},
  author={Cai, Xingyu and Huang, Jiaji and Bian, Yifan and Church, Kenneth},
  journal={arXiv preprint arXiv:2110.09330},
  year={2021}
}

% === INTERPRETABILITY ===

@article{elhage2022toy,
  title={Toy Models of Superposition},
  author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and others},
  journal={arXiv preprint arXiv:2209.10652},
  year={2022}
}

@article{nanda2023progress,
  title={Progress Measures for Grokking via Mechanistic Interpretability},
  author={Nanda, Neel and Chan, Lawrence and Lieberum, Tom and Smith, Jess and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2301.05217},
  year={2023}
}

% === KERNEL METHODS ===

@inproceedings{rahimi2007random,
  title={Random Features for Large-Scale Kernel Machines},
  author={Rahimi, Ali and Recht, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  volume={20},
  year={2007}
}

@article{gittens2016revisiting,
  title={Revisiting the Nystr{\"o}m Method for Improved Large-scale Machine Learning},
  author={Gittens, Alex and Mahoney, Michael W},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={3977--4041},
  year={2016}
}

@article{alaoui2015fast,
  title={Fast Randomized Kernel Ridge Regression with Statistical Guarantees},
  author={Alaoui, Ahmed and Mahoney, Michael W},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  year={2015}
}

% === PRIVACY COMPOSITION ===

@inproceedings{mironov2017renyi,
  title={R{\'e}nyi Differential Privacy},
  author={Mironov, Ilya},
  booktitle={2017 IEEE 30th Computer Security Foundations Symposium (CSF)},
  pages={263--275},
  year={2017},
  organization={IEEE}
}

@inproceedings{rogers2016privacy,
  title={Privacy Odometers and Filters: Pay-as-you-go Composition},
  author={Rogers, Ryan and Roth, Aaron and Ullman, Jonathan and Vadhan, Salil},
  booktitle={Advances in Neural Information Processing Systems},
  volume={29},
  year={2016}
}

@article{feldman2021individual,
  title={Individual Privacy Accounting via a R{\'e}nyi Filter},
  author={Feldman, Vitaly and Zrnic, Tijana},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

% === MULTI-AGENT SYSTEMS ===

@article{wu2023autogen,
  title={AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation},
  author={Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Zhang, Shaokun and Zhu, Erkang and Li, Beibin and Jiang, Li and Zhang, Xiaoyun and Wang, Chi},
  journal={arXiv preprint arXiv:2308.08155},
  year={2023}
}

@article{talebirad2023multi,
  title={Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents},
  author={Talebirad, Yashar and Nadiri, Amirhossein},
  journal={arXiv preprint arXiv:2306.03314},
  year={2023}
}

% === FEDERATED LEARNING ===

@inproceedings{mcmahan2017communication,
  title={Communication-Efficient Learning of Deep Networks from Decentralized Data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial Intelligence and Statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

@inproceedings{bonawitz2017practical,
  title={Practical Secure Aggregation for Privacy-Preserving Machine Learning},
  author={Bonawitz, Keith and Ivanov, Vladimir and Kreuter, Ben and Marcedone, Antonio and McMahan, H Brendan and Patel, Sarvar and Ramage, Daniel and Segal, Aaron and Seth, Karn},
  booktitle={Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  pages={1175--1191},
  year={2017}
}

% === REGULATORY ===

@article{voigt2017gdpr,
  title={The EU General Data Protection Regulation (GDPR)},
  author={Voigt, Paul and Von dem Bussche, Axel},
  journal={A Practical Guide, 1st Ed., Cham: Springer International Publishing},
  volume={10},
  number={3152676},
  pages={10--5555},
  year={2017},
  publisher={Springer}
}

@article{hipaa1996,
  title={Health Insurance Portability and Accountability Act of 1996},
  author={{U.S. Congress}},
  journal={Public Law},
  volume={104},
  number={191},
  year={1996}
}

% === VERIFICATION ===

@inproceedings{miculicich2025veriguard,
  title={VeriGuard: Verification-Guided Safety in LLM Agents},
  author={Miculicich, Lesly and Chen, Xiang and Li, Wei},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2025}
}

@inproceedings{katz2017reluplex,
  title={Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks},
  author={Katz, Guy and Barrett, Clark and Dill, David L and Julian, Kyle and Kochenderfer, Mykel J},
  booktitle={International Conference on Computer Aided Verification},
  pages={97--117},
  year={2017},
  organization={Springer}
}

% === ERASING CONCEPTS ===

@article{gandikota2023erasing,
  title={Erasing Concepts from Diffusion Models},
  author={Gandikota, Rohit and Materzynska, Joanna and Fiotto-Kaufman, Jared and Bau, David},
  journal={arXiv preprint arXiv:2303.07345},
  year={2023}
}

@article{kumari2023ablating,
  title={Ablating Concepts in Text-to-Image Diffusion Models},
  author={Kumari, Nupur and Zhang, Bingliang and Zhang, Richard and Shechtman, Eli and Zhu, Jun-Yan},
  journal={arXiv preprint arXiv:2303.13516},
  year={2023}
}

% === ADDITIONAL AGENT SAFETY ===

@article{ruan2023identifying,
  title={Identifying the Risks of LM Agents with an LM-Emulated Sandbox},
  author={Ruan, Yangjun and Dong, Honghua and Wang, Andrew and Pitis, Silviu and Zhou, Yongchao and Ba, Jimmy and Dubois, Yann and Maddison, Chris J and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2309.15817},
  year={2023}
}

@article{yang2024swe,
  title={SWE-Agent: Agent-Computer Interfaces Enable Automated Software Engineering},
  author={Yang, John and Jimenez, Carlos E and Wettig, Alexander and Liber, Kilian and Narasimhan, Shunyu and Press, Ofir},
  journal={arXiv preprint arXiv:2405.15793},
  year={2024}
}

% === DATA MINIMIZATION ===

@article{biega2020operationalizing,
  title={Operationalizing the Legal Principle of Data Minimization for Personalization},
  author={Biega, Asia J and Potash, Peter and Daumé III, Hal and Diaz, Fernando and Finck, Michèle},
  journal={Proceedings of the 2020 ACM SIGIR},
  year={2020}
}

% === TOOL USE ===

@article{schick2024toolformer,
  title={Toolformer: Language Models Can Teach Themselves to Use Tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dessì, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{qin2023tool,
  title={Tool Learning with Foundation Models},
  author={Qin, Yujia and Liang, Shengding and Ye, Yining and Zhu, Kunlun and Yan, Lan and Lu, Yaxi and Lin, Yankai and Cong, Xin and Tang, Xiangru and Qian, Bill and others},
  journal={arXiv preprint arXiv:2304.08354},
  year={2023}
}

% === COMPETITOR BENCHMARKS ===

@article{bagdasaryan2025agentdam,
  title={AgentDAM: Privacy Leakage Evaluation for Autonomous Web Agents},
  author={Bagdasaryan, Eugene and Wu, Ren and Wen, Huan and Bhaskar, Siddharth and Boneh, Dan and Tramèr, Florian},
  journal={Advances in Neural Information Processing Systems},
  volume={38},
  year={2025}
}

@article{shao2024privacylens,
  title={PrivacyLens: Evaluating Privacy Norm Awareness of Language Models in Action},
  author={Shao, Yijia and Li, Tianshi and Liu, Yanchen and Shi, Weiyan and Yang, Diyi},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  year={2024}
}

@article{wu2024airgapagent,
  title={AirGapAgent: Protecting Privacy for LLM Agents through Data Minimization},
  author={Wu, Ruihan and Hsieh, Chun-Yin and Chen, Jingxing and Zhong, Zhiyu and Zhang, Ce},
  journal={arXiv preprint arXiv:2405.05175},
  year={2024}
}

% === GUARDRAIL SYSTEMS ===

@misc{meta2024promptguard,
  title={PromptGuard: A Real-Time Defense Against Prompt Injection Attacks},
  author={{Meta AI}},
  year={2024},
  howpublished={\url{https://github.com/meta-llama/PurpleLlama/tree/main/Prompt-Guard}},
  note={Accessed: December 2025}
}

@misc{nvidia2024nemo,
  title={NeMo Guardrails: A Toolkit for Adding Programmable Guardrails to LLM-based Applications},
  author={{NVIDIA}},
  year={2024},
  howpublished={\url{https://github.com/NVIDIA/NeMo-Guardrails}},
  note={Accessed: December 2025}
}

@article{meta2024llamaguard,
  title={Llama Guard 3: A Foundation Model for Human-AI Conversation Safety},
  author={Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and Khabsa, Madian},
  journal={arXiv preprint arXiv:2412.06026},
  year={2024}
}

@misc{lakera2024guard,
  title={Lakera Guard: AI Security for Production Applications},
  author={{Lakera AI}},
  year={2024},
  howpublished={\url{https://www.lakera.ai/lakera-guard}},
  note={Accessed: December 2025}
}

@misc{rebuff2023,
  title={Rebuff: LLM Prompt Injection Detector},
  author={{Protect AI}},
  year={2023},
  howpublished={\url{https://github.com/protectai/rebuff}},
  note={Accessed: December 2025}
}
